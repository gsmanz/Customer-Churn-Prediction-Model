# üß† Predicci√≥n de Churn (Fuga de Clientes)

## 1. üìå Descripci√≥n

Este proyecto tiene como objetivo desarrollar un modelo de *machine learning* para predecir la probabilidad de que un cliente abandone un servicio (*churn*).  
Se ha llevado a cabo un completo proceso de limpieza, preprocesamiento y modelado de datos.

La soluci√≥n implementada incluye la construcci√≥n de un **pipeline** que automatiza las etapas de imputaci√≥n, transformaci√≥n, reducci√≥n de dimensionalidad y entrenamiento del modelo. Se emplea un enfoque modular para facilitar la mantenibilidad y la reproducibilidad del modelo.

---

## 2. üóÇÔ∏è Contenido del Repositorio

La estructura del repositorio es la siguiente:

üìÅ data/ # Contiene el dataset original
üìÅ notebooks/ # Incluye notebooks para exploraci√≥n, limpieza, pipelines y modelado
üìÑ churn_model.pkl # Modelo entrenado serializado
üìÑ README.md # Este archivo
üìÑ .gitignore # Archivos a ignorar por Git


---

## 3. üõ†Ô∏è Librer√≠as Utilizadas

El proyecto emplea las siguientes librer√≠as y frameworks principales:

- **An√°lisis y visualizaci√≥n:** `pandas`, `numpy`, `matplotlib`, `seaborn`  
- **Preprocesamiento:** `scikit-learn`, `imblearn`  
- **Modelado:** `scikit-learn`, `XGBoost`, `CatBoost`  
- **Interpretabilidad:** `shap`  
- **Persistencia:** `pickle`  
- **Warnings:** `warnings`  

---

## 4. ‚öôÔ∏è Metodolog√≠a de Preprocesamiento

El pipeline de preprocesamiento y modelado se estructura en los siguientes pasos:

### üîπ Imputaci√≥n de valores nulos
- Imputaci√≥n constante con valor `'Unknown'` para variables categ√≥ricas con alta proporci√≥n de nulos (`area`, `ownrent`, etc.).
- Imputaci√≥n con `0.0`, mediana o valor m√°s frecuente, seg√∫n el tipo y distribuci√≥n de la variable.

### üîπ Reducci√≥n de cardinalidad
- Implementaci√≥n de **CumsumVarFilter**, que agrupa categor√≠as poco frecuentes bajo la etiqueta `'other'` seg√∫n un umbral acumulado de frecuencia (90%).

### üîπ Transformaci√≥n de variables
- **Categ√≥ricas:** One-Hot Encoding (`OneHotEncoder`)  
- **Num√©ricas:** Normalizaci√≥n (`StandardScaler`)

### üîπ Reducci√≥n de dimensionalidad
- **Alta correlaci√≥n:** Eliminaci√≥n de variables altamente correlacionadas entre s√≠ (`> 0.9`), conservando la que mejor se correlaciona con el objetivo.
- **Baja varianza:** Eliminaci√≥n de variables con varianza menor a un umbral definido (`0.05`)

---

## 5. ü§ñ Modelado

Se probaron m√∫ltiples algoritmos de clasificaci√≥n, entre ellos:

- `LogisticRegression`
- `RandomForestClassifier`
- `GradientBoostingClassifier`
- `XGBClassifier`
- `CatBoostClassifier` (modelo final seleccionado)

El modelo final fue entrenado dentro de un **pipeline completo** que incluye todo el flujo de preprocesamiento mencionado anteriormente.

**M√©trica principal de evaluaci√≥n:**  
`f1_score` sobre el conjunto de test:

> **F1-score (X_test):** `0.839`

---

## 6. üßÆ Interpretabilidad

Se emple√≥ la librer√≠a **SHAP** para interpretar las predicciones del modelo y entender qu√© variables tienen mayor peso en la predicci√≥n del churn.

---

## 7. ‚ôªÔ∏è Reproducibilidad

El pipeline completo ha sido construido con `scikit-learn` y puede ser reutilizado para nuevos datasets simplemente cargando el modelo entrenado:

```python
import pickle

with open("churn_model.pkl", "rb") as file:
    model = pickle.load(file)
